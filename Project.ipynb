{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import scipy.stats\n",
    "import utils\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data_source = 'project_data/yelp.csv' #done; also have full labels\n",
    "amazon_instant_source = 'project_data/reviews_Amazon_Instant_Video_5.json' #done; also have full labels\n",
    "amazon_instruments_source = 'project_data/reviews_Musical_Instruments_5.json' #done; have full labels\n",
    "amazon_music_source = 'project_data/reviews_Digital_Music_5.json'#done; have full labels\n",
    "rate_beer_source = 'project_data/ratebeer.txt'# done; have full labels\n",
    "amazon_beauty_source = 'project_data/reviews_Beauty_5.json' #have full labels\n",
    "sources = [yelp_data_source, amazon_instruments_source, amazon_music_source, amazon_instant_source, rate_beer_source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    '''\n",
    "    Returns a tuple (X, y)\n",
    "    X is matrix \n",
    "    y is vector of ratings\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(path, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        i = 0\n",
    "        for line in reader:\n",
    "            #hacky way of skipping the header...\n",
    "            if i == 0:\n",
    "                i+=1\n",
    "                continue\n",
    "            rating = int(line[3])\n",
    "            #hacky way of removing new lines\n",
    "            text = \" \".join(line[4].split())\n",
    "            X.append(text)\n",
    "            y.append(rating)\n",
    "    print(\"Loaded: {}\".format(path))\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_to_csv(output_filename, X = None, y = None, path=None, force_binary = True):\n",
    "    '''\n",
    "    Write to nvidia compliant format\n",
    "    label,sentence\n",
    "    y,x\n",
    "    y,x\n",
    "    etc.\n",
    "    \n",
    "    Provide path if loading from source\n",
    "    '''\n",
    "    if not X and not y and not path:\n",
    "        print(\"Must provide data source from file or from numpy.\")\n",
    "        return\n",
    "    \n",
    "    with open(output_filename, \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"label\", \"sentence\"])\n",
    "        if not (path is None):\n",
    "            X,y = load_csv(path) if path.split(\".\")[-1]==\"csv\" else load_json_from_text(path)\n",
    "        for label, example in zip(y,X):\n",
    "            if force_binary:\n",
    "                new_label = 0 if label < 3 else 1 #force binary labels\n",
    "            else:\n",
    "                new_label = label\n",
    "            writer.writerow([new_label, example])\n",
    "    print(\"Conversion for {} finished. Written to {}.\".format(path, output_filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/yelp.csv\n",
      "Conversion for project_data/yelp.csv finished. Written to yelp_nvidia.csv.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_json_from_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7655f4ce4203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwrite_to_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"yelp_nvidia.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myelp_data_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwrite_to_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"instruments_nvidia.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamazon_instruments_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwrite_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"music_nvidia.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamazon_music_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwrite_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"instant_nvidia.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamazon_instant_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7d332902af3b>\u001b[0m in \u001b[0;36mwrite_to_csv\u001b[0;34m(output_filename, X, y, path, force_binary)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"csv\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mload_json_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce_binary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_json_from_text' is not defined"
     ]
    }
   ],
   "source": [
    "write_to_csv( \"yelp_nvidia.csv\",path=yelp_data_source)\n",
    "write_to_csv( \"instruments_nvidia.csv\",path=amazon_instruments_source)\n",
    "write_to_csv(\"music_nvidia.csv\",path=amazon_music_source)\n",
    "write_to_csv(\"instant_nvidia.csv\",path=amazon_instant_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_from_text(source):\n",
    "    '''\n",
    "    Built for amazon Jsons\n",
    "    Returns a tuple (X, y)\n",
    "    X is matrix \n",
    "    y is vector of ratings\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(source, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['reviewText']\n",
    "            if len(text) > 1:\n",
    "                X.append(text)\n",
    "                rating = int(data['overall'])\n",
    "                y.append(rating)\n",
    "            \n",
    "    print(\"Loaded: {}\".format(source))\n",
    "    return (X, y)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Beauty_5.json\n"
     ]
    }
   ],
   "source": [
    "X,y = load_json_from_text(amazon_beauty_source)\n",
    "X,y = X[:10000], y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rate_beer_from_text(ratebeer_source):\n",
    "    X = []\n",
    "    y = []\n",
    "    #cp1252 since this source was compiled on a windows machine\n",
    "    with open(ratebeer_source, \"r\", encoding = 'cp1252') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.split(\":\")[0] == 'review/overall':\n",
    "                y.append(int(line.split(\":\")[1].split(\"/\")[0]))\n",
    "            if line.split(\":\")[0] == 'review/text':\n",
    "                if len(line.split(\":\")) > 2: #to account for UPDATED:\n",
    "                    X.append(line.split(\":\")[2])\n",
    "                else:\n",
    "                    X.append(line.split(\":\")[1])\n",
    "            if len(X) == 10000 and len(y) == 10000: #hard cap at 100\n",
    "                break\n",
    "    print(\"Loaded: {}\".format(ratebeer_source))\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/ratebeer.txt\n"
     ]
    }
   ],
   "source": [
    "X, y = load_rate_beer_from_text(rate_beer_source)\n",
    "X,y = X[:10000], y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(sources):\n",
    "    X = []\n",
    "    y = []\n",
    "    for source in sources:\n",
    "        if source.split(\".\")[-1] == 'json':\n",
    "            a,b = load_json_from_text(source)\n",
    "            X += a\n",
    "            y += b\n",
    "        elif source.split(\".\")[-1] == 'csv':\n",
    "            a,b = load_csv(source)\n",
    "            X += a\n",
    "            y += b \n",
    "        elif source.split(\".\")[-1] == 'txt':\n",
    "            a,b = load_rate_beer_from_text(source)\n",
    "            X += a\n",
    "            y += b\n",
    "    return (X[:10000], y[:10000]) #hard cap at 10,000 reviews\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Musical_Instruments_5.json\n",
      "Number of datapoints loaded: 10000\n"
     ]
    }
   ],
   "source": [
    "sources = [amazon_instruments_source]\n",
    "X,y = collect_data(sources)\n",
    "print(\"Number of datapoints loaded: {}\".format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, dev, test split\n",
    "#random state = 42 for all splits\n",
    "def split_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)\n",
    "    print(\"train: {}, dev: {}, test: {}\".format(len(X_train), len(X_dev), len(X_test)))\n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_and_save_labels(X,y, name = None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)\n",
    "    print(\"train: {}, dev: {}, test: {}\".format(len(X_train), len(X_dev), len(X_test)))\n",
    "    if name:\n",
    "        np.save('{}_trY'.format(name), y_train)\n",
    "        np.save('{}_vaY'.format(name), y_dev)\n",
    "        np.save('{}_teY'.format(name), y_test)\n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 8100, dev: 900, test: 1000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_dev, X_test, y_train, y_dev, y_test = split_data_and_save_labels(X,y, \"beauty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion for None finished. Written to amazon_beauty_train.csv.\n",
      "Conversion for None finished. Written to amazon_beauty_val.csv.\n",
      "Conversion for None finished. Written to amazon_beauty_test.csv.\n"
     ]
    }
   ],
   "source": [
    "#write to nvidia compliant format\n",
    "write_to_csv(\"amazon_beauty_train.csv\", X = X_train, y = y_train)\n",
    "write_to_csv(\"amazon_beauty_val.csv\", X = X_dev, y = y_dev)\n",
    "write_to_csv(\"amazon_beauty_test.csv\", X = X_test, y = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_phi(x):\n",
    "    '''\n",
    "    unigram feature applied to each example\n",
    "    Removes case\n",
    "    Removes punctuation\n",
    "    '''\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    x = x.translate(translator)\n",
    "    return Counter(x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ternary_class_func(y):\n",
    "    \"\"\"Define a binary SST task. Just like `binary_class_func` except\n",
    "    input '2' returns 'neutral'.\"\"\"\n",
    "    if y in (\"0\", \"1\"):\n",
    "        return \"negative\"\n",
    "    elif y in (\"3\", \"4\"):\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "    \n",
    "def binary_class_func(y, lower = 1, upper = 5):\n",
    "    \n",
    "    span = range(1,upper + 1)\n",
    "    median = span[int(len(span)/2)]\n",
    "    \n",
    "    if y < median:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "def identity_class_func(y):\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(X,y, phi = (1,1), max_features = 15000, class_func = identity_class_func, vectorizer=None, vectorize=True, beer_args = {}):\n",
    "    \"\"\"Core general function for building experimental datasets.\n",
    "    Uses CountVectorizer from sklearn to encapsulate n-gram feature generation and vectorization.\n",
    "\n",
    "    vectorize : bool\n",
    "       Whether to use a CountVectorizer. Set this to False for\n",
    "       deep learning models that process their own input.\n",
    "    phi: (a,b)\n",
    "        Range for n-grams. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict with keys 'X' (the feature matrix), 'y' (the list of\n",
    "        labels), 'vectorizer' (the `DictVectorizer`), and\n",
    "        'raw_examples' (the `nltk.Tree` objects, for error analysis).\n",
    "\n",
    "    \"\"\"\n",
    "    raw_examples = X\n",
    "    if class_func == binary_class_func:\n",
    "        labels = [class_func(l, **beer_args) for l in y]\n",
    "    else:\n",
    "        labels = [class_func(l) for l in y]\n",
    "    feat_matrix = None\n",
    "    \n",
    "    if vectorize:\n",
    "        \n",
    "        # In training, we want a new vectorizer:\n",
    "        if vectorizer == None:\n",
    "            vectorizer = CountVectorizer(max_features = max_features, ngram_range = phi)\n",
    "            feat_matrix = vectorizer.fit_transform(X)\n",
    "            \n",
    "        # In assessment, we featurize using the existing vectorizer:\n",
    "        else:\n",
    "            feat_matrix = vectorizer.transform(X)\n",
    "            \n",
    "    else:\n",
    "        feat_matrix = feat_dicts\n",
    "        \n",
    "    return {'X': feat_matrix,\n",
    "            'y': labels,\n",
    "            'vectorizer': vectorizer,\n",
    "            'raw_examples': raw_examples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset with features has 8,100 examples and 15,000 features\n"
     ]
    }
   ],
   "source": [
    "train_dataset = build_dataset(X_train, y_train, class_func = binary_class_func)\n",
    "print(\"Train dataset with features has {:,} examples and {:,} features\".format(\n",
    "        *train_dataset['X'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev dataset with features has 900 examples and 15,000 features\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = build_dataset(X_dev, y_dev, class_func = binary_class_func, vectorizer = train_dataset['vectorizer'])\n",
    "print(\"Dev dataset with features has {:,} examples and {:,} features\".format(\n",
    "        *dev_dataset['X'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset with features has 1,000 examples and 15,000 features\n"
     ]
    }
   ],
   "source": [
    "test_dataset = build_dataset(X_test, y_test, class_func = binary_class_func, vectorizer = train_dataset['vectorizer'])\n",
    "print(\"test dataset with features has {:,} examples and {:,} features\".format(\n",
    "        *test_dataset['X'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y,args_dict = {}):    \n",
    "    '''\n",
    "    max ent classifier (multi class log reg)\n",
    "    '''\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y, **args_dict)\n",
    "    return mod\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "def fit_basic_sgd_classifier(X, y,args_dict = {}):    \n",
    "    \"\"\"Wrapper for `BasicSGDClassifier`.    \n",
    "    \"\"\"    \n",
    "    mod = SGDClassifier()\n",
    "    mod.fit(X, y, **args_dict)\n",
    "    return mod\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def fit_rf_classifier(X,y, args_dict = {}):\n",
    "    mod = RandomForestClassifier(**args_dict)\n",
    "    mod.fit(X,y)\n",
    "    return mod\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def fit_sgb_classifier(X,y, args_dict = {}):\n",
    "    mod = GradientBoostingClassifier(**args_dict)\n",
    "    mod.fit(X,y)\n",
    "    return mod\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def fit_mnb_classifier(X,y, args_dict = {}):\n",
    "    mod = MultinomialNB(**args_dict)\n",
    "    mod.fit(X,y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "        train_func,\n",
    "        X,\n",
    "        y,\n",
    "        phi = (1,1),\n",
    "        assess=None,\n",
    "        max_features = 15000,\n",
    "        class_func=identity_class_func,\n",
    "        score_func=utils.safe_macro_f1,\n",
    "        vectorize=True,\n",
    "        verbose=True, \n",
    "        args_dict = {},\n",
    "        beer_args = {}):\n",
    "    \"\"\"\n",
    "    \n",
    "    Convenience function.\n",
    "    \n",
    "    If assess is none, performance on training is reported. Otherwise, performance on assess = (X_assess, y_assess) is reported.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Model\n",
    "    \n",
    "    float\n",
    "        The overall scoring metric as determined by `score_metric`.\n",
    "\n",
    "    \"\"\"\n",
    "    # Train dataset:\n",
    "    train = build_dataset(X, y, class_func = class_func, phi = phi, max_features = max_features, beer_args = beer_args)\n",
    "    \n",
    "    # Manage the assessment set-up:\n",
    "    X_train = train['X']\n",
    "    y_train = train['y']\n",
    "    X_assess = train['X']\n",
    "    y_assess = train['y']\n",
    "    if assess != None:\n",
    "        X_dev, y_dev = assess\n",
    "        dev = build_dataset(X_dev, y_dev, class_func = class_func, phi = phi, vectorizer = train['vectorizer'], beer_args = beer_args)\n",
    "        X_assess, y_assess = dev['X'], dev['y']\n",
    "    # Train:\n",
    "    mod = train_func(X_train, y_train, args_dict)\n",
    "    # Predictions:\n",
    "    predictions = mod.predict(X_assess)\n",
    "    # Report:\n",
    "    if verbose:\n",
    "        print('Accuracy: %0.03f' % accuracy_score(y_assess, predictions))\n",
    "        print(classification_report(y_assess, predictions, digits=3))\n",
    "    # Return the overall score:\n",
    "    return mod, score_func(y_assess, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.830     0.293     0.433       150\n",
      "          1      0.888     0.989     0.936       850\n",
      "\n",
      "avg / total      0.879     0.885     0.861      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgdmodel, score = experiment(fit_basic_sgd_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = binary_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.908\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.727     0.620     0.669       150\n",
      "          1      0.935     0.959     0.947       850\n",
      "\n",
      "avg / total      0.903     0.908     0.905      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxentmodel, score = experiment(fit_maxent_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = binary_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.596     0.218     0.320       142\n",
      "          1      0.869     0.972     0.918       758\n",
      "\n",
      "avg / total      0.826     0.853     0.823       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args_dict = {\"n_estimators\": 10}\n",
    "rfmodel, score = experiment(fit_rf_classifier, X_train, y_train, phi = (1,1), assess = (X_dev, y_dev), class_func = binary_class_func, args_dict = args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.876\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.842     0.213     0.340       150\n",
      "          1      0.877     0.993     0.932       850\n",
      "\n",
      "avg / total      0.872     0.876     0.843      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args_dict = {}\n",
    "sgbmodel, score = experiment(fit_sgb_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = binary_class_func, args_dict = args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.667     0.600     0.632       150\n",
      "          1      0.931     0.947     0.939       850\n",
      "\n",
      "avg / total      0.891     0.895     0.893      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args_dict = {\"alpha\": 0.08}\n",
    "mnbmodel, score = experiment(fit_mnb_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = binary_class_func, args_dict = args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_battery(source, beer_args = {}, class_func = binary_class_func):\n",
    "    '''\n",
    "    specify beer rating limits in beer_args if using binary labels on beer dataset\n",
    "    fit sgd, log reg, rf, sgb, mnb models on unigram features on source\n",
    "    '''\n",
    "    sources = [source]\n",
    "    X,y = collect_data(sources)\n",
    "    print(\"Number of datapoints loaded: {}\".format(len(X)))\n",
    "    \n",
    "    X_train, X_dev, X_test, y_train, y_dev, y_test = split_data(X,y)\n",
    "    \n",
    "    print(\"Log Reg Model\")\n",
    "    maxentmodel, score = experiment(fit_maxent_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = class_func, beer_args = beer_args)\n",
    "    \n",
    "    print(\"RF Model\")\n",
    "    args_dict = {\"n_estimators\": 10}\n",
    "    rfmodel, score = experiment(fit_rf_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = class_func, args_dict = args_dict, beer_args = beer_args)\n",
    "    \n",
    "    print(\"SGB Model\")\n",
    "    args_dict = {}\n",
    "    sgbmodel, score = experiment(fit_sgb_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = class_func, args_dict = args_dict, beer_args = beer_args)\n",
    "    \n",
    "    print(\"SGD Model\")\n",
    "    args_dict = {}\n",
    "    sgdmodel, score = experiment(fit_basic_sgd_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = class_func, beer_args = beer_args)\n",
    "    \n",
    "    print(\"MNB Model\")\n",
    "    args_dict = {\"alpha\": 0.08}\n",
    "    mnbmodel, score = experiment(fit_mnb_classifier, X_train, y_train, phi = (1,1), assess = (X_test, y_test), class_func = class_func, args_dict = args_dict, beer_args = beer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Amazon_Instant_Video_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.940\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.714     0.333     0.455        75\n",
      "          1      0.948     0.989     0.968       925\n",
      "\n",
      "avg / total      0.931     0.940     0.930      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.750     0.040     0.076        75\n",
      "          1      0.928     0.999     0.962       925\n",
      "\n",
      "avg / total      0.914     0.927     0.896      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.930\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.778     0.093     0.167        75\n",
      "          1      0.931     0.998     0.963       925\n",
      "\n",
      "avg / total      0.920     0.930     0.904      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.595     0.333     0.427        75\n",
      "          1      0.948     0.982     0.964       925\n",
      "\n",
      "avg / total      0.921     0.933     0.924      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.931\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.543     0.507     0.524        75\n",
      "          1      0.960     0.965     0.963       925\n",
      "\n",
      "avg / total      0.929     0.931     0.930      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_instant_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Digital_Music_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.500     0.171     0.255        35\n",
      "          1      0.971     0.994     0.982       965\n",
      "\n",
      "avg / total      0.954     0.965     0.957      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.000     0.000     0.000        35\n",
      "          1      0.965     1.000     0.982       965\n",
      "\n",
      "avg / total      0.931     0.965     0.948      1000\n",
      "\n",
      "SGB Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.500     0.057     0.103        35\n",
      "          1      0.967     0.998     0.982       965\n",
      "\n",
      "avg / total      0.951     0.965     0.951      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.964\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.471     0.229     0.308        35\n",
      "          1      0.973     0.991     0.982       965\n",
      "\n",
      "avg / total      0.955     0.964     0.958      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.960\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.407     0.314     0.355        35\n",
      "          1      0.975     0.983     0.979       965\n",
      "\n",
      "avg / total      0.955     0.960     0.958      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_music_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Musical_Instruments_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.941\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.400     0.185     0.253        54\n",
      "          1      0.955     0.984     0.969       946\n",
      "\n",
      "avg / total      0.925     0.941     0.931      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.946\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.500     0.056     0.100        54\n",
      "          1      0.949     0.997     0.972       946\n",
      "\n",
      "avg / total      0.924     0.946     0.925      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.942\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.000     0.000     0.000        54\n",
      "          1      0.946     0.996     0.970       946\n",
      "\n",
      "avg / total      0.895     0.942     0.918      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.198     0.296     0.237        54\n",
      "          1      0.959     0.931     0.945       946\n",
      "\n",
      "avg / total      0.918     0.897     0.907      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.939\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.360     0.167     0.228        54\n",
      "          1      0.954     0.983     0.968       946\n",
      "\n",
      "avg / total      0.922     0.939     0.928      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_instruments_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/ratebeer.txt\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.590     0.383     0.465        94\n",
      "          1      0.938     0.972     0.955       906\n",
      "\n",
      "avg / total      0.906     0.917     0.909      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.904\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.450     0.096     0.158        94\n",
      "          1      0.913     0.988     0.949       906\n",
      "\n",
      "avg / total      0.870     0.904     0.875      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.765     0.138     0.234        94\n",
      "          1      0.918     0.996     0.955       906\n",
      "\n",
      "avg / total      0.903     0.915     0.887      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.510     0.277     0.359        94\n",
      "          1      0.928     0.972     0.950       906\n",
      "\n",
      "avg / total      0.889     0.907     0.894      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.900\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.474     0.574     0.519        94\n",
      "          1      0.955     0.934     0.944       906\n",
      "\n",
      "avg / total      0.910     0.900     0.904      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(rate_beer_source, beer_args = {\"lower\": 1, \"upper\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/yelp.csv\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.908\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.727     0.620     0.669       150\n",
      "          1      0.935     0.959     0.947       850\n",
      "\n",
      "avg / total      0.903     0.908     0.905      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.625     0.200     0.303       150\n",
      "          1      0.874     0.979     0.923       850\n",
      "\n",
      "avg / total      0.837     0.862     0.830      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.874\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.816     0.207     0.330       150\n",
      "          1      0.876     0.992     0.930       850\n",
      "\n",
      "avg / total      0.867     0.874     0.840      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.699     0.667     0.683       150\n",
      "          1      0.942     0.949     0.946       850\n",
      "\n",
      "avg / total      0.905     0.907     0.906      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.895\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.667     0.600     0.632       150\n",
      "          1      0.931     0.947     0.939       850\n",
      "\n",
      "avg / total      0.891     0.895     0.893      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(yelp_data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_experiment(source_name, args = {}):\n",
    "    '''\n",
    "    feature extraction from language model\n",
    "\n",
    "    source_name is for example \"yelp\"\n",
    "    then we feed \"yelp_trY.npy\" etc as source to np.load\n",
    "    \n",
    "    Does both a binary and a full label log reg based on features\n",
    "    '''\n",
    "    y = np.load(\"project_data/{}_trY.npy\".format(source_name))\n",
    "    X = np.load(\"project_data/{}_trXt.npy\".format(source_name))\n",
    "    vaX = np.load(\"project_data/{}_vaXt.npy\".format(source_name))\n",
    "    vaY = np.load(\"project_data/{}_vaY.npy\".format(source_name))\n",
    "    teX = np.load(\"project_data/{}_teXt.npy\".format(source_name))\n",
    "    teY = np.load(\"project_data/{}_teY.npy\".format(source_name))\n",
    "\n",
    "    print(\"All labels classification\")\n",
    "    model = fit_maxent_classifier(X, y)\n",
    "    predictions = model.predict(teX)\n",
    "    print('Accuracy: %0.03f' % accuracy_score(teY, predictions))\n",
    "    print(classification_report(teY, predictions, digits=3))\n",
    "\n",
    "\n",
    "    print(\"Binary classification\")\n",
    "    y = [binary_class_func(i, **args) for i in y]\n",
    "    model = fit_maxent_classifier(X, y)\n",
    "    predictions = model.predict(teX)\n",
    "    teY = [binary_class_func(i, **args) for i in teY]\n",
    "    print('Accuracy: %0.03f' % accuracy_score(teY, predictions))\n",
    "    print(classification_report(teY, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.510\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.593     0.500     0.543        70\n",
      "          2      0.393     0.438     0.414        80\n",
      "          3      0.372     0.288     0.325       156\n",
      "          4      0.511     0.518     0.514       367\n",
      "          5      0.571     0.627     0.598       327\n",
      "\n",
      "avg / total      0.505     0.510     0.506      1000\n",
      "\n",
      "Binary classification\n",
      "Accuracy: 0.915\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.707     0.740     0.723       150\n",
      "          1      0.954     0.946     0.950       850\n",
      "\n",
      "avg / total      0.917     0.915     0.916      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#currently data is mLSTM featurization on yelp reviews \n",
    "nn_experiment(\"yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.727     0.400     0.516        40\n",
      "          2      0.333     0.229     0.271        35\n",
      "          3      0.244     0.268     0.256        82\n",
      "          4      0.368     0.354     0.361       229\n",
      "          5      0.770     0.808     0.789       614\n",
      "\n",
      "avg / total      0.618     0.623     0.618      1000\n",
      "\n",
      "Binary classification\n",
      "Accuracy: 0.954\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.738     0.600     0.662        75\n",
      "          1      0.968     0.983     0.975       925\n",
      "\n",
      "avg / total      0.951     0.954     0.952      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#amazon instant reviews \n",
    "nn_experiment(\"instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.700\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.529     0.375     0.439        24\n",
      "          2      0.250     0.133     0.174        30\n",
      "          3      0.345     0.247     0.288        77\n",
      "          4      0.342     0.358     0.350       176\n",
      "          5      0.831     0.873     0.852       693\n",
      "\n",
      "avg / total      0.683     0.700     0.690      1000\n",
      "\n",
      "Binary classification\n",
      "Accuracy: 0.963\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.707     0.537     0.611        54\n",
      "          1      0.974     0.987     0.981       946\n",
      "\n",
      "avg / total      0.960     0.963     0.961      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_experiment(\"instruments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.000     0.000     0.000        20\n",
      "          9      0.000     0.000     0.000        15\n",
      "         10      0.208     0.143     0.169        35\n",
      "         11      0.089     0.095     0.092        42\n",
      "         12      0.165     0.177     0.171        79\n",
      "         13      0.149     0.214     0.176        84\n",
      "         14      0.203     0.185     0.194       135\n",
      "         15      0.178     0.218     0.196       133\n",
      "         16      0.191     0.200     0.195       150\n",
      "         17      0.160     0.197     0.176       117\n",
      "         18      0.268     0.250     0.259       104\n",
      "         19      0.357     0.114     0.172        44\n",
      "         20      0.000     0.000     0.000        18\n",
      "\n",
      "avg / total      0.179     0.179     0.175      1000\n",
      "\n",
      "Binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.443     0.287     0.348        94\n",
      "          1      0.929     0.962     0.945       906\n",
      "\n",
      "avg / total      0.883     0.899     0.889      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#args passes in lower and upper limit of scores so we can compute threshold\n",
    "nn_experiment(\"beer\", args = {'lower':1, 'upper':20}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.659\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.400     0.143     0.211        14\n",
      "          2      0.429     0.143     0.214        21\n",
      "          3      0.375     0.265     0.310        68\n",
      "          4      0.358     0.320     0.338       228\n",
      "          5      0.765     0.842     0.801       669\n",
      "\n",
      "avg / total      0.633     0.659     0.642      1000\n",
      "\n",
      "Binary classification\n",
      "Accuracy: 0.967\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.536     0.429     0.476        35\n",
      "          1      0.979     0.987     0.983       965\n",
      "\n",
      "avg / total      0.964     0.967     0.965      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_experiment(\"music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels classification\n",
      "Accuracy: 0.154\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.500     0.250     0.333         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.000     0.000     0.000        20\n",
      "          9      0.000     0.000     0.000        15\n",
      "         10      0.258     0.229     0.242        35\n",
      "         11      0.111     0.071     0.087        42\n",
      "         12      0.122     0.127     0.124        79\n",
      "         13      0.134     0.179     0.153        84\n",
      "         14      0.134     0.148     0.141       135\n",
      "         15      0.167     0.218     0.189       133\n",
      "         16      0.191     0.173     0.182       150\n",
      "         17      0.159     0.205     0.179       117\n",
      "         18      0.158     0.115     0.133       104\n",
      "         19      0.200     0.091     0.125        44\n",
      "         20      0.200     0.111     0.143        18\n",
      "\n",
      "avg / total      0.153     0.154     0.150      1000\n",
      "\n",
      "Binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.419     0.330     0.369        94\n",
      "          1      0.932     0.953     0.942       906\n",
      "\n",
      "avg / total      0.884     0.894     0.888      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_experiment(\"beer8k\", args = {'lower':1, 'upper':20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Amazon_Instant_Video_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.617\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.429     0.150     0.222        40\n",
      "          2      0.067     0.029     0.040        35\n",
      "          3      0.353     0.293     0.320        82\n",
      "          4      0.355     0.328     0.341       229\n",
      "          5      0.738     0.832     0.783       614\n",
      "\n",
      "avg / total      0.583     0.617     0.595      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.500     0.025     0.048        40\n",
      "          2      0.000     0.000     0.000        35\n",
      "          3      0.364     0.098     0.154        82\n",
      "          4      0.362     0.205     0.262       229\n",
      "          5      0.663     0.909     0.766       614\n",
      "\n",
      "avg / total      0.540     0.614     0.545      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.833     0.125     0.217        40\n",
      "          2      0.250     0.029     0.051        35\n",
      "          3      0.238     0.061     0.097        82\n",
      "          4      0.407     0.153     0.222       229\n",
      "          5      0.660     0.950     0.779       614\n",
      "\n",
      "avg / total      0.560     0.629     0.548      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.346     0.225     0.273        40\n",
      "          2      0.120     0.086     0.100        35\n",
      "          3      0.263     0.183     0.216        82\n",
      "          4      0.324     0.646     0.431       229\n",
      "          5      0.821     0.581     0.681       614\n",
      "\n",
      "avg / total      0.618     0.532     0.549      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.603\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.348     0.200     0.254        40\n",
      "          2      0.097     0.086     0.091        35\n",
      "          3      0.312     0.293     0.302        82\n",
      "          4      0.352     0.245     0.289       229\n",
      "          5      0.721     0.834     0.773       614\n",
      "\n",
      "avg / total      0.566     0.603     0.579      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_instant_source, class_func = identity_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Digital_Music_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      1.000     0.214     0.353        14\n",
      "          2      0.200     0.048     0.077        21\n",
      "          3      0.302     0.191     0.234        68\n",
      "          4      0.394     0.325     0.356       228\n",
      "          5      0.750     0.854     0.799       669\n",
      "\n",
      "avg / total      0.630     0.662     0.638      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.646\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.000     0.000     0.000        14\n",
      "          2      1.000     0.095     0.174        21\n",
      "          3      0.000     0.000     0.000        68\n",
      "          4      0.267     0.088     0.132       228\n",
      "          5      0.677     0.933     0.784       669\n",
      "\n",
      "avg / total      0.535     0.646     0.559      1000\n",
      "\n",
      "SGB Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.690\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.500     0.071     0.125        14\n",
      "          2      0.000     0.000     0.000        21\n",
      "          3      0.250     0.015     0.028        68\n",
      "          4      0.541     0.145     0.228       228\n",
      "          5      0.702     0.979     0.818       669\n",
      "\n",
      "avg / total      0.617     0.690     0.603      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.527\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.167     0.071     0.100        14\n",
      "          2      0.286     0.095     0.143        21\n",
      "          3      0.197     0.191     0.194        68\n",
      "          4      0.304     0.671     0.418       228\n",
      "          5      0.859     0.535     0.659       669\n",
      "\n",
      "avg / total      0.665     0.527     0.554      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.666\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.333     0.286     0.308        14\n",
      "          2      0.300     0.143     0.194        21\n",
      "          3      0.304     0.250     0.274        68\n",
      "          4      0.406     0.399     0.403       228\n",
      "          5      0.789     0.824     0.806       669\n",
      "\n",
      "avg / total      0.652     0.666     0.658      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_music_source, class_func = identity_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/reviews_Musical_Instruments_5.json\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.675\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.429     0.125     0.194        24\n",
      "          2      0.333     0.067     0.111        30\n",
      "          3      0.373     0.247     0.297        77\n",
      "          4      0.307     0.290     0.298       176\n",
      "          5      0.779     0.866     0.820       693\n",
      "\n",
      "avg / total      0.643     0.675     0.652      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.000     0.000     0.000        24\n",
      "          2      0.500     0.033     0.062        30\n",
      "          3      0.600     0.039     0.073        77\n",
      "          4      0.269     0.102     0.148       176\n",
      "          5      0.709     0.947     0.811       693\n",
      "\n",
      "avg / total      0.600     0.678     0.596      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.705\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.333     0.042     0.074        24\n",
      "          2      0.000     0.000     0.000        30\n",
      "          3      0.625     0.065     0.118        77\n",
      "          4      0.419     0.102     0.164       176\n",
      "          5      0.721     0.983     0.832       693\n",
      "\n",
      "avg / total      0.629     0.705     0.616      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.644\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.333     0.042     0.074        24\n",
      "          2      0.000     0.000     0.000        30\n",
      "          3      0.269     0.416     0.327        77\n",
      "          4      0.290     0.239     0.262       176\n",
      "          5      0.789     0.821     0.805       693\n",
      "\n",
      "avg / total      0.627     0.644     0.631      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.651\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.308     0.167     0.216        24\n",
      "          2      0.000     0.000     0.000        30\n",
      "          3      0.298     0.182     0.226        77\n",
      "          4      0.269     0.244     0.256       176\n",
      "          5      0.761     0.851     0.804       693\n",
      "\n",
      "avg / total      0.605     0.651     0.625      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(amazon_instruments_source, class_func = identity_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/yelp.csv\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.652     0.429     0.517        70\n",
      "          2      0.429     0.412     0.420        80\n",
      "          3      0.385     0.301     0.338       156\n",
      "          4      0.477     0.488     0.482       367\n",
      "          5      0.526     0.612     0.566       327\n",
      "\n",
      "avg / total      0.487     0.489     0.485      1000\n",
      "\n",
      "RF Model\n",
      "Accuracy: 0.422\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.292     0.100     0.149        70\n",
      "          2      0.192     0.062     0.094        80\n",
      "          3      0.260     0.173     0.208       156\n",
      "          4      0.418     0.575     0.484       367\n",
      "          5      0.504     0.526     0.515       327\n",
      "\n",
      "avg / total      0.395     0.422     0.396      1000\n",
      "\n",
      "SGB Model\n",
      "Accuracy: 0.489\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.645     0.286     0.396        70\n",
      "          2      0.450     0.113     0.180        80\n",
      "          3      0.491     0.167     0.249       156\n",
      "          4      0.451     0.621     0.523       367\n",
      "          5      0.527     0.630     0.574       327\n",
      "\n",
      "avg / total      0.496     0.489     0.460      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.480\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.600     0.386     0.470        70\n",
      "          2      0.400     0.075     0.126        80\n",
      "          3      0.297     0.474     0.365       156\n",
      "          4      0.497     0.477     0.487       367\n",
      "          5      0.584     0.606     0.595       327\n",
      "\n",
      "avg / total      0.494     0.480     0.473      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.500\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.441     0.429     0.435        70\n",
      "          2      0.397     0.312     0.350        80\n",
      "          3      0.381     0.276     0.320       156\n",
      "          4      0.490     0.572     0.528       367\n",
      "          5      0.587     0.587     0.587       327\n",
      "\n",
      "avg / total      0.494     0.500     0.494      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(yelp_data_source, class_func = identity_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: project_data/ratebeer.txt\n",
      "Number of datapoints loaded: 10000\n",
      "train: 8100, dev: 900, test: 1000\n",
      "Log Reg Model\n",
      "Accuracy: 0.211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.250     0.150     0.187        20\n",
      "          9      0.000     0.000     0.000        15\n",
      "         10      0.091     0.057     0.070        35\n",
      "         11      0.154     0.143     0.148        42\n",
      "         12      0.215     0.215     0.215        79\n",
      "         13      0.215     0.238     0.226        84\n",
      "         14      0.252     0.230     0.240       135\n",
      "         15      0.157     0.195     0.174       133\n",
      "         16      0.210     0.247     0.227       150\n",
      "         17      0.229     0.282     0.253       117\n",
      "         18      0.312     0.288     0.300       104\n",
      "         19      0.200     0.091     0.125        44\n",
      "         20      0.167     0.111     0.133        18\n",
      "\n",
      "avg / total      0.207     0.211     0.207      1000\n",
      "\n",
      "RF Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.158\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.167     0.050     0.077        20\n",
      "          9      0.000     0.000     0.000        15\n",
      "         10      0.029     0.029     0.029        35\n",
      "         11      0.083     0.071     0.077        42\n",
      "         12      0.202     0.241     0.220        79\n",
      "         13      0.209     0.274     0.237        84\n",
      "         14      0.142     0.148     0.145       135\n",
      "         15      0.164     0.233     0.193       133\n",
      "         16      0.164     0.187     0.174       150\n",
      "         17      0.159     0.188     0.173       117\n",
      "         18      0.149     0.067     0.093       104\n",
      "         19      0.167     0.023     0.040        44\n",
      "         20      0.400     0.111     0.174        18\n",
      "\n",
      "avg / total      0.156     0.158     0.149      1000\n",
      "\n",
      "SGB Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.000     0.000     0.000         0\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.250     0.050     0.083        20\n",
      "          9      0.000     0.000     0.000        15\n",
      "         10      0.000     0.000     0.000        35\n",
      "         11      0.000     0.000     0.000        42\n",
      "         12      0.291     0.203     0.239        79\n",
      "         13      0.196     0.107     0.138        84\n",
      "         14      0.183     0.170     0.176       135\n",
      "         15      0.181     0.308     0.228       133\n",
      "         16      0.212     0.327     0.257       150\n",
      "         17      0.200     0.325     0.248       117\n",
      "         18      0.219     0.154     0.181       104\n",
      "         19      0.200     0.023     0.041        44\n",
      "         20      0.222     0.111     0.148        18\n",
      "\n",
      "avg / total      0.184     0.196     0.177      1000\n",
      "\n",
      "SGD Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/envs/nlu/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.154\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.000     0.000     0.000         0\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.125     0.050     0.071        20\n",
      "          9      0.038     0.067     0.049        15\n",
      "         10      0.147     0.143     0.145        35\n",
      "         11      0.120     0.143     0.130        42\n",
      "         12      0.138     0.101     0.117        79\n",
      "         13      0.160     0.048     0.073        84\n",
      "         14      0.179     0.304     0.225       135\n",
      "         15      0.139     0.105     0.120       133\n",
      "         16      0.150     0.060     0.086       150\n",
      "         17      0.183     0.291     0.224       117\n",
      "         18      0.253     0.231     0.241       104\n",
      "         19      0.125     0.091     0.105        44\n",
      "         20      0.068     0.167     0.097        18\n",
      "\n",
      "avg / total      0.157     0.154     0.145      1000\n",
      "\n",
      "MNB Model\n",
      "Accuracy: 0.195\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1      0.000     0.000     0.000         0\n",
      "          2      0.000     0.000     0.000         1\n",
      "          3      0.000     0.000     0.000         2\n",
      "          4      0.000     0.000     0.000         2\n",
      "          5      0.000     0.000     0.000         4\n",
      "          6      0.000     0.000     0.000         7\n",
      "          7      0.000     0.000     0.000         8\n",
      "          8      0.200     0.050     0.080        20\n",
      "          9      0.111     0.067     0.083        15\n",
      "         10      0.136     0.086     0.105        35\n",
      "         11      0.068     0.071     0.070        42\n",
      "         12      0.229     0.278     0.251        79\n",
      "         13      0.168     0.202     0.184        84\n",
      "         14      0.208     0.156     0.178       135\n",
      "         15      0.169     0.173     0.171       133\n",
      "         16      0.219     0.227     0.223       150\n",
      "         17      0.230     0.299     0.260       117\n",
      "         18      0.246     0.298     0.270       104\n",
      "         19      0.111     0.068     0.085        44\n",
      "         20      0.067     0.056     0.061        18\n",
      "\n",
      "avg / total      0.188     0.195     0.188      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linear_battery(rate_beer_source, beer_args = {\"lower\":1, \"upper\":20}, class_func = identity_class_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
